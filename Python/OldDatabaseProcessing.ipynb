{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import time\n",
    "import ast\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import powerlaw\n",
    "from collections import defaultdict\n",
    "from srm.db_manager import connect_to_db, execute_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name, table = \"bidisha\", \"copaWordCup\"\n",
    "cursor_mysql, conn = connect_to_db(\"localhost\", \"root\", \"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotData(data, start, end):\n",
    "    count = 0\n",
    "    bins = np.linspace(start, end, 10)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(data.keys())))\n",
    "    #print colors\n",
    "    #colors = ['r', 'b', 'g', 'w', 'y', 'o', ''\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    moddata=defaultdict(list)\n",
    "    \n",
    "    for k in data.keys():\n",
    "        timestamp=data[k]\n",
    "        for time in timestamp:\n",
    "            if time>=start and time<=end :\n",
    "                moddata.setdefault(k,[]).append(time)\n",
    "    \n",
    "    for (c,k) in zip(colors, data):\n",
    "        #print k\n",
    "        #k = unicode(k, \"utf-8\")\n",
    "        count+=1\n",
    "        plt.hist(moddata[k], bins, label = k, histtype='step', color = c)\n",
    "    plt.yscale('log')\n",
    "    plt.legend(loc='upper right', prop={'size':10})\n",
    "    plt.xlabel('Tweeted time', fontsize=18)\n",
    "    plt.ylabel('Tweet volume', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getuniquehashtag():\n",
    "    results = execute_sql(\"Select distinct(hashtags) from %s.%s\", (db_name, table))\n",
    "    #hashtagMod1, hashtagMod2, hashtagMod3))\n",
    "    hashtagName = []               \n",
    "    for row in results:\n",
    "            hashtagName.extend(row[0].split(','))\n",
    "    return list(set(hashtagName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relativetimestamp(hashtags):\n",
    "    dicthashtag = defaultdict(list)\n",
    "    mintimestamp = [row[0] for row in execute_sql('Select min(created_at) from %s.%s',(db_name, table))]\n",
    "    mintimestamp = int(time.mktime(mintimestamp[0].timetuple()))\n",
    "    for hashtag in hashtags:\n",
    "        hashtagMod1 = '\\\"%'+hashtag.strip()+',%\\\"'\n",
    "        hashtagMod2 = '\\\"%,'+hashtag.strip()+'%\\\"'\n",
    "        hashtagMod3 = '\\\"'+hashtag.strip()+'\\\"'\n",
    "        timestamps = [row[0] for row in execute_sql(\"Select created_at from %s.%s where\\\n",
    "        (hashTags like %s OR hashTags like %s OR hashTags like %s) \\\n",
    "        order by created_at;\", (db_name, table, hashtagMod1, hashtagMod2, hashtagMod3))]\n",
    "        relativetimestamps = [(int(time.mktime(x.timetuple())) - mintimestamp) for x in timestamps]\n",
    "        tempstr=','.join(str(x) for x in relativetimestamps)\n",
    "        dicthashtag[hashtag] = relativetimestamps\n",
    "    return dicthashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatehtFromFile(filename):\n",
    "    f = open(filename)\n",
    "    hashtaglist = []\n",
    "    for line in f:\n",
    "        hashtaglist.append(line.split(\"\\t\")[0])\n",
    "    return hashtaglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp(hashtags, c):\n",
    "    dicthashtag = defaultdict(list)\n",
    "    for hashtag in hashtags:\n",
    "        timestamps = [row[0] for row in c.execute('Select UnixTimeStamp from hashtagUsageInfo where Hashtag=\\\\\n",
    "    '+'\\\"'+hashtag+'\\\"'+'order by UnixTimeStamp')]\n",
    "        relativetimestamps = [(x - timestamps[0]) for x in timestamps]\n",
    "        tempstr=','.join(str(x) for x in relativetimestamps)\n",
    "        dicthashtag[hashtag] = relativetimestamps\n",
    "    return dicthashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateDataFromFile(filename):\n",
    "    f = open(filename)\n",
    "    dicthashtag = defaultdict(list)\n",
    "    for line in f:\n",
    "        tokens = line.strip().split(\"\\t\")\n",
    "        hashtag = tokens[0]\n",
    "        #print hashtag\n",
    "        timestamp = ast.literal_eval(tokens[1])\n",
    "        dicthashtag[hashtag] = timestamp\n",
    "    return dicthashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateRank(dicthashtag, starttime, endtime, k):\n",
    "    popularity_count = defaultdict(int)\n",
    "    for key in dicthashtag.keys():\n",
    "        timestamplist = dicthashtag[key]\n",
    "        #print key,timestamplist\n",
    "        for ts in timestamplist:\n",
    "            if(ts>=starttime and ts<=endtime):\n",
    "                popularity_count.setdefault(key, 0)\n",
    "                popularity_count[key]+=1\n",
    "    #print popularity_count\n",
    "    sortedpc = sorted(popularity_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #sortedpc = sorted(popularity_count, key=popularity_count.get, reverse=True)\n",
    "    #print sortedpc\n",
    "    topk = [row[0] for row in sortedpc[:k]]\n",
    "    print topk\n",
    "    resultDict = defaultdict(int)\n",
    "    for tk in topk:\n",
    "        #print defaultdict[tk]\n",
    "        resultDict[tk] = dicthashtag[tk]\n",
    "    return resultDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagList = getuniquehashtag()\n",
    "hashtagmap = relativetimestamp(hashtagList)\n",
    "f = open(\"/home/bidisha/2017-hashtag-code/Data/\"+table+\"relative.txt\",\"a\")\n",
    "countmap = defaultdict(list)\n",
    "for hashtag in hashtagmap.keys():\n",
    "    timestamps = hashtagmap[hashtag]\n",
    "    if len(timestamps) > 200:\n",
    "        countmap[hashtag] = len(timestamps)\n",
    "        f.write(hashtag+\"\\t\")\n",
    "f.close()\n",
    "f = open(\"/home/bidisha/2017-hashtag-code/Data/\"+table+\".txt\",\"a\")\n",
    "for hashtag in countmap.keys():\n",
    "    f.write(hashtag+\"\\t\"+str(countmap[hashtag])+\"\\n\")\n",
    "    #print hashtag, countmap[hashtag]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hashtagdict = generateDataFromFile(\"/home/bidisha/2017-hashtag-code/Data/BaselineDisaster_Nepalrelative.txt\")\n",
    "hashtagList = generatehtFromFile(\"/home/bidisha/2017-hashtag-code/Data/hashtags/Disaster_Nepal_mini.txt\")\n",
    "\n",
    "#hashtagdict = generateDataFromFile(\"/home/bidisha/2017-hashtag-code/Data/Hillaryrelative.txt\")\n",
    "#hashtagList = generatehtFromFile(\"/home/bidisha/2017-hashtag-code/Data/hashtags/Hillary.txt\")\n",
    "\n",
    "newhtdict = defaultdict(list)\n",
    "for key in hashtagList:\n",
    "    key = key.strip()\n",
    "    newhtdict[key] = hashtagdict[key]\n",
    "\n",
    "#print newhtdict\n",
    "#plotData(newhtdict, 0,1296000)\n",
    "#plotData(newhtdict, 432000,1296000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nepalquake', 'nepalquak', 'prayfornepal', 'earth', 'pray', 'prayfor', 'kathmandu', 'nepalquakerelief', 'indiawithnepal', 'NepalDisasterReliefByMSG', 'withnepal', 'NepalDisaster', 'earthquakeagain', 'nepaldisasterrelief', 'nepalquakeagain', 'quakerelief', 'langtang', 'MSGHelpEarthquakeVictims', 'Soulvulture', 'prayer', 'victims', 'quakeagain', 'terremoto', 'earthquakevictims', 'redcross', 'terremotonepal', 'helpnepal', 'mounteverest', 'staystrong', 'bangladesh']\n",
      "['nepalquake', 'prayfornepal', 'nepalquak', 'earth', 'pray', 'prayfor', 'kathmandu', 'nepalquakerelief', 'earthquakeagain', 'nepalquakeagain', 'indiawithnepal', 'withnepal', 'quakeagain', 'Soulvulture', 'prayer', 'NepalDisasterReliefByMSG', 'quakerelief', 'redcross', 'langtang', 'mounteverest', 'terremoto', 'prayersfornepal', 'staystrong', 'MSGHelpEarthquakeVictims', 'terremotonepal', 'bangladesh', 'nepalquake2015', 'helpnepal', 'kathmanduquake', 'victims']\n",
      "['nepalquake', 'nepalquak', 'prayfornepal', 'pray', 'earth', 'kathmandu', 'prayfor', 'nepalquakerelief', 'indiawithnepal', 'withnepal', 'quakerelief', 'NepalDisasterReliefByMSG', 'langtang', 'terremoto', 'terremotonepal', 'Soulvulture', 'helpnepal', 'MSGHelpEarthquakeVictims', 'prayer', 'redcross', 'victims', 'kathmanduquake', 'earthquakevictims', 'staystrong', 'mounteverest', 'bangladesh', 'prayersfornepal', 'aftershock', 'staysafe', 'standwithnepal']\n",
      "set(['kathmanduquake', 'staystrong', 'prayer', 'langtang', 'quakerelief', 'earth', 'NepalDisasterReliefByMSG', 'bangladesh', 'pray', 'terremotonepal', 'prayfornepal', 'nepalquak', 'victims', 'MSGHelpEarthquakeVictims', 'helpnepal', 'redcross', 'nepalquakerelief', 'prayersfornepal', 'withnepal', 'Soulvulture', 'terremoto', 'mounteverest', 'nepalquake', 'prayfor', 'kathmandu', 'indiawithnepal'])\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "tempdict = calculateRank(newhtdict, 0, 1296000, 30)\n",
    "#print tempdict\n",
    "tempdict1 = calculateRank(newhtdict, 0, 86400, 30)\n",
    "tempdict2 = calculateRank(newhtdict, 86400, 162800, 30)\n",
    "\n",
    "#tempdict1 = calculateRank(newhtdict, 345600, 691200, 100)\n",
    "#tempdict2 = calculateRank(newhtdict, 518400,777600, 100)\n",
    "print (set(tempdict1).intersection(tempdict2))\n",
    "print set(tempdict2).intersection(tempdict3)\n",
    "#tempdict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
