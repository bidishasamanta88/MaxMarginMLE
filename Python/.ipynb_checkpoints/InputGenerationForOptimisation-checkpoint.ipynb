{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import time\n",
    "import ast\n",
    "import math\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import curve_fit\n",
    "from srm.db_manager import connect_to_db, execute_sql\n",
    "#from Utility.dataProcessing import *\n",
    "import powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_name, table = \"bidisha\", \"icct20\"\n",
    "cursor_mysql, conn = connect_to_db(\"localhost\", \"root\", \"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatehtFromFile(filename):\n",
    "    f = open(filename)\n",
    "    hashtaglist = []\n",
    "    for line in f:\n",
    "        hashtaglist.append(line.split(\"\\t\")[0].strip())\n",
    "    return hashtaglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp(hashtags):\n",
    "    dicthashtag = defaultdict(list)\n",
    "    maxts = 0\n",
    "    mints = sys.maxint\n",
    "    for hashtag in hashtags:\n",
    "        hashtag = hashtag.strip()\n",
    "        hashtagMod1 = '\\\"%'+hashtag.strip()+',%\\\"'\n",
    "        hashtagMod2 = '\\\"%,'+hashtag.strip()+'%\\\"'\n",
    "        hashtagMod3 = '\\\"'+hashtag.strip()+'\\\"'\n",
    "        timestamps = [row[0] for row in execute_sql(\"Select created_at from %s.%s where\\\n",
    "        (hashTags like %s OR hashTags like %s OR hashTags like %s) \\\n",
    "        order by created_at;\", (db_name, table, hashtagMod1, hashtagMod2, hashtagMod3))]\n",
    "        inttimestamps = [int(time.mktime(x.timetuple())) for x in timestamps]\n",
    "        tempstr=','.join(str(x) for x in inttimestamps)\n",
    "        if(inttimestamps[0] < mints):\n",
    "            mints = inttimestamps[0]\n",
    "        if(inttimestamps[-1] > maxts):\n",
    "            maxts = inttimestamps[-1]\n",
    "        dicthashtag[hashtag] = inttimestamps\n",
    "    return (dicthashtag, maxts, mints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generatechainlist(hashtaglist, klistfile):\n",
    "    for hashtag in hashtaglist:\n",
    "        hashtag = hashtag.strip()\n",
    "        f = open(klistfile+hashtag+\".txt\",'a')\n",
    "        hashtagMod1 = '\\\"%'+hashtag.strip()+',%\\\"'\n",
    "        hashtagMod2 = '\\\"%,'+hashtag.strip()+'%\\\"'\n",
    "        hashtagMod3 = '\\\"'+hashtag.strip()+'\\\"'\n",
    "        pidlist = [row[0] for row in execute_sql(\"Select distinct(parent_id_str) FROM %s.%s where\\\n",
    "        (hashTags like %s OR hashTags like %s OR hashTags like %s) and (parent_id_str is not NULL)\\\n",
    "        ;\",(db_name, table, hashtagMod1, hashtagMod2, hashtagMod3))]\n",
    "        for pid in pidlist:\n",
    "            tweetchain = [int(time.mktime(row[0].timetuple())) for row in execute_sql(\"Select created_at \\\n",
    "            FROM %s.%s where (hashTags like %s OR hashTags like %s OR hashTags like %s) and (parent_id_str=%s)\\\n",
    "            order by created_at;\",(db_name, table, hashtagMod1, hashtagMod2, hashtagMod3,pid))]\n",
    "            f.write(pid+\"\\t[\"+\",\".join([str(x) for x in tweetchain])+\"]\\n\")             \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createbucketlist(dictHashtag, mints, maxts, noofbuckets):\n",
    "    bucketsize = (maxts - mints) / noofbuckets\n",
    "    bucketlist = defaultdict(list)\n",
    "    for hashtag in dictHashtag.keys():\n",
    "        hashtag = hashtag.strip()\n",
    "        timeseries = dictHashtag[hashtag]\n",
    "        #print hashtag, timeseries[0], timeseries[-1]\n",
    "        for i in range(0,noofbuckets):\n",
    "            start = mints + i * bucketsize\n",
    "            end = mints + (i+1) * bucketsize\n",
    "            #print start, end\n",
    "            #if(timeseries[0] > end or timeseries[-1]< start):\n",
    "            count = 0\n",
    "            for t in timeseries:\n",
    "                if (t >= start and t <=end) :\n",
    "                    count += 1        \n",
    "            bucketlist[i].append((hashtag,count))\n",
    "    for i in range(0,noofbuckets):\n",
    "        hl = bucketlist[i]\n",
    "        shl = [row[0] for row in sorted(hl, key=lambda tup: tup[1])][:5]\n",
    "        bucketlist[i] = shl\n",
    "    #print shl\n",
    "    return bucketlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getKarray(klistfile, hashtag, start, end, train, bincount):\n",
    "    f = open(klistfile+hashtag+\".txt\")\n",
    "    finalcount = 0\n",
    "    #print hashtag\n",
    "    minchain =  sys.maxint\n",
    "    maxchain = 1\n",
    "    chaindict = defaultdict(int)\n",
    "    c = 0\n",
    "    reversetimedict = defaultdict(int)\n",
    "    for line in f:\n",
    "        timestamplist = ast.literal_eval(line.split(\"\\t\")[1])\n",
    "        #print timestamplist\n",
    "        count = 1\n",
    "        c = c+1\n",
    "        for ts in timestamplist:\n",
    "            reversetimedict[ts-start] = c\n",
    "            #if (ts >= start and ts <= end):\n",
    "                #continue\n",
    "            #    print \"insde\"\n",
    "            count = count + 1\n",
    "        if maxchain < count:\n",
    "            maxchain = count\n",
    "        if minchain > count:\n",
    "            minchain = count\n",
    "        finalcount += count\n",
    "        chaindict[c] = count\n",
    "        #print c, count\n",
    "    karray = []\n",
    "    #print \"train\", train\n",
    "    for ts in train:\n",
    "        if ts in reversetimedict.keys():\n",
    "            karray.append(chaindict[reversetimedict[ts]])\n",
    "        else:\n",
    "            karray.append(1)\n",
    "    #print minchain, maxchain\n",
    "    #print karray\n",
    "    bins = np.linspace(minchain, maxchain, bincount)\n",
    "    karray_mod = np.array(np.digitize(karray,bins))\n",
    "    #print karray_mod\n",
    "    results = powerlaw.Fit(karray_mod)\n",
    "    print results.power_law.alpha\n",
    "    return (karray,results.power_law.alpha)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrelativerank(hashtagList, start, end, dictHashtag, rankfilename):\n",
    "    continuation = (end - start)/4\n",
    "    #ranklist = defaultdict(list)\n",
    "    counthash = defaultdict(int)\n",
    "    s = start\n",
    "    f = open(rankfilename, \"a\")\n",
    "    for i in range(0,4):\n",
    "        e = s + continuation\n",
    "        for hashtag in hashtagList:\n",
    "            hashtag = hashtag.strip()\n",
    "            ts = dictHashtag[hashtag]\n",
    "            count = 0\n",
    "            for t in ts:\n",
    "                if (t >= start and t<=e):\n",
    "                    count = count + 1\n",
    "            counthash[hashtag] = count\n",
    "        sorted_h = [hashtagList.index(key) for (key, value) in  sorted(counthash.items(),key=operator.itemgetter(1))]\n",
    "        f.write(str(s - start) + \"\\t\"+ str(e-start)+\"\\t\"+\"\\t\".join([str(x) for x in sorted_h])+\"\\n\")\n",
    "        s = s + continuation\n",
    "        #print i\n",
    "    f.close()\n",
    "        #ranklist[i] = sorted_h\n",
    "#return ranklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createInput(dictHashtag,mints, maxts, noofbuckets, klistfile, outputfile):\n",
    "    bucketsize = (maxts - mints) / noofbuckets\n",
    "    bucketlist = createbucketlist(dictHashtag, mints, maxts, noofbuckets)\n",
    "    #print bucketlist\n",
    "    for i in range(0, noofbuckets):\n",
    "        hashtaglist = bucketlist[i]\n",
    "        start = mints + i * bucketsize\n",
    "        end = mints + bucketsize + i * bucketsize\n",
    "        index = start + 0.8 * bucketsize\n",
    "        fw = open(outputfile+str(i)+\"name.txt\", \"a\")\n",
    "        fw.write(\",\".join(hashtaglist))\n",
    "        fw.close()\n",
    "        f = open(outputfile+str(i)+\".txt\", \"a\")\n",
    "        #print \"start\", start, end, hashtaglist\n",
    "        \n",
    "        for hashtag in hashtaglist:\n",
    "            #print \"hello\"\n",
    "            hashtag = hashtag.strip()\n",
    "            #print hashtag\n",
    "            timeseries = dictHashtag[hashtag]\n",
    "            relative = [(x - mints) for x in timeseries]\n",
    "            train = [x for x in relative if (x <=index and x>=start and x <= end)]\n",
    "            test = [x for x in relative if  (x > index and x>=start and x<=end)]\n",
    "            (karray,alpha) = getKarray(klistfile,hashtag,start, end, train, 1000)\n",
    "            #print \"hello2\"\n",
    "            print \"tarin\", train\n",
    "            #print \"test\", test\n",
    "            #karray\n",
    "            f.write(\",\".join([str(x) for x in karray])+\"\\n\")\n",
    "            #arrival\n",
    "            f.write(\",\".join([str(x) for x in train])+\"\\n\")\n",
    "            #omega\n",
    "            f.write(\"0.01\"+\"\\n\")\n",
    "            #omega_0\n",
    "            f.write(\"0.01\"+\"\\n\")\n",
    "            #alpha\n",
    "            f.write(str(alpha)+\"\\n\")\n",
    "            #initial parameters\n",
    "            f.write(\"0.01,0.01\"+\"\\n\")\n",
    "            #test set\n",
    "            f.write(\",\".join(str(x) for x in test)+\"\\n\")\n",
    "        f.close()\n",
    "        #break\n",
    "        getrelativerank(hashtaglist,start, end, dictHashtag, outfile+\"rank\"+str(i)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ICC_T20', 'IndvNZ', 'IndvsPak', 'PakvBaN', 'T20WORLDCUP', 'T20world', 'WorldT20', 'WorldT20Heroes', 'aus', 'cricket', 'iccwt20', 'india', 'indvpak', 'indvspa', 'pakistan', 'worldcup']\n"
     ]
    }
   ],
   "source": [
    "#main block\n",
    "#name of the file with hashtaglist\n",
    "filename = \"/home/bidisha/2017-hashtag-code/Data/hashtags/candidateHashtag.txt\"\n",
    "#directory name for the chain files\n",
    "klistfile = \"/home/bidisha/2017-hashtag-code/Data/hashtags/chain/\"\n",
    "hashtaglist = generatehtFromFile(filename)\n",
    "print hashtaglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "generatechainlist(hashtaglist, klistfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457196848 1458402525\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n",
      "Calculating best minimal value for power law fit\n",
      "Less than 2 unique data values left after xmin and xmax options! Cannot fit. Returning nans.\n",
      "Not enough data. Returning nan\n",
      "Not enough data. Returning nan\n"
     ]
    }
   ],
   "source": [
    "klistfile = \"/home/bidisha/2017-hashtag-code/Data/hashtags/chain/\"\n",
    "(dictHahstag,maxts,mints) = timestamp(hashtaglist)\n",
    "outfile = \"/home/bidisha/2017-hashtag-code/Data/hashtags/output/\"\n",
    "print mints, maxts\n",
    "createInput(dictHahstag,mints, maxts, 5 , klistfile, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
